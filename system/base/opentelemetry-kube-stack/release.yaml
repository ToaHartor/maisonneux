apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: opentelemetry-kube-stack
  namespace: opentelemetry
spec:
  releaseName: opentelemetry-kube-stack
  dependsOn:
    - name: prometheus-operator-crds
  chart:
    spec:
      chart: opentelemetry-kube-stack
      # renovate: datasource=helm depName=opentelemetry-kube-stack registryUrl=https://open-telemetry.github.io/opentelemetry-helm-charts
      version: "0.6.2"
      sourceRef:
        kind: HelmRepository
        name: open-telemetry
        namespace: flux-system
  interval: 50m
  install:
    remediation:
      retries: 3
  values:
    # https://github.com/open-telemetry/opentelemetry-helm-charts/blob/main/charts/opentelemetry-kube-stack/values.yaml
    crds:
      installOtel: true
      installPrometheus: false # Installed by prometheus-operator-crds chart

    opentelemetry-operator:
      # Subchart values https://github.com/open-telemetry/opentelemetry-helm-charts/blob/main/charts/opentelemetry-operator/values.yaml
      enabled: true
      manager:
        collectorImage:
          repository: otel/opentelemetry-collector-contrib

        resources:
          limits:
            cpu: 100m
            memory: 128Mi
            ephemeral-storage: 50Mi
          requests:
            cpu: 100m
            memory: 64Mi
            ephemeral-storage: 50Mi

      crds:
        create: false # Disable as we install the CRDs globally
      
      replicaCount: 2 # Number of hypervisors

      pdb:
        create: true
        minAvailable: 1
      
      topologySpreadConstraints:
        # Maximum 1 pod per Proxmox hypervisor
        - maxSkew: 1
          topologyKey: topology.kubernetes.io/zone
          whenUnsatisfiable: ScheduleAnyway
          labelSelector:
            matchLabels:
              app.kubernetes.io/name: opentelemetry-operator
              app.kubernetes.io/component: controller-manager
        # Maximum 1 pod per node. If only one worker remains, then only one replica is enough
        - maxSkew: 1
          topologyKey: kubernetes.io/hostname
          whenUnsatisfiable: DoNotSchedule
          labelSelector:
            matchLabels:
              app.kubernetes.io/name: opentelemetry-operator
              app.kubernetes.io/component: controller-manager

    defaultCRConfig:

      observability:
        metrics:
          enableMetrics: true

      config:
        service:
          # Otel debug logs
          telemetry:
            logs:
              level: DEBUG
          pipelines:
            metrics:
              exporters: &victoriametrics-exporter [otlphttp/victoriametrics, debug]
        
        exporters:
          otlphttp/victoriametrics:
            compression: gzip
            encoding: proto
            # URL format from https://docs.victoriametrics.com/victoriametrics/cluster-victoriametrics/#url-format
            metrics_endpoint: http://vminsert-metrics-datastore.monitoring.svc.cluster.local:8480/insert/0/opentelemetry/v1/metrics
            logs_endpoint: http://vlinsert-logs-datastore.monitoring.svc.cluster.local:9481/insert/opentelemetry/v1/logs
            tls:
              insecure: true

    collectors:
      targetallocator:
        enabled: true
        replicas: 1
        mode: statefulset
        # Collecting ServiceMonitor and PodMonitor resources
        # We dedicate a pod to collect targetAllocator metrics, and the other for scrape annotations
        targetAllocator:
          replicas: 1
          enabled: true
          # allocationStrategy: per-node
          filterStrategy: relabel-config
          prometheusCR:
            enabled: true
            podMonitorSelector: {}
            serviceMonitorSelector: {}

        podDisruptionBudget:
          minAvailable: 1

        presets:
          kubernetesAttributes:
            enabled: true

        config:
          receivers:
            prometheus:
              config:
                scrape_configs:
                # Overriden by targetAllocator config
                - job_name: 'otel-collector'
                  scrape_interval: 10s
                  static_configs:
                  - targets: [ '0.0.0.0:8888' ]
                  metric_relabel_configs:
                  - action: labeldrop
                    regex: (id|name)
                    replacement: $$$$1
                  - action: labelmap
                    regex: label_(.+)
                    replacement: $$$$1

          processors:
            batch:
              send_batch_max_size: 1500
              send_batch_size: 1000
              timeout: 1s
          exporters:
            debug: {}
          service:
            pipelines:
              metrics:
                receivers: [prometheus]
                processors: [k8sattributes, batch]
                exporters: *victoriametrics-exporter

      daemon:
        enabled: true

        presets:
          logsCollection:
            enabled: true
            includeCollectorLogs: false
          kubeletMetrics:
            enabled: true
          hostMetrics:
            enabled: true
          kubernetesAttributes:
            enabled: true
        
        # Should run as root to collect hostMetrics
        securityContext:
          # readOnlyRootFilesystem:
          runAsNonRoot: false
          runAsUser: 0
          runAsGroup: 0

        # Tolerations to schedule daemon pods on control-plane nodes
        tolerations:
          - key: node-role.kubernetes.io/control-plane
            effect: NoSchedule

        scrape_configs_file: ""

        config:
          receivers:
            # Prometheus collector config
            prometheus:
              config:
                global:
                  scrape_timeout: 10s
                scrape_configs:
                # Prometheus scraping, from https://github.com/open-telemetry/opentelemetry-helm-charts/blob/main/charts/opentelemetry-kube-stack/daemon_scrape_configs.yaml
                  - job_name: kubernetes-pods
                    scrape_interval: 30s
                    kubernetes_sd_configs:
                      - role: pod
                        selectors:
                          - role: pod
                            # only scrape data from pods running on the same node as collector
                            field: "spec.nodeName=$${env:OTEL_K8S_NODE_NAME}"
                    relabel_configs:
                      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                        action: keep
                        regex: true
                      - source_labels:
                          [__meta_kubernetes_pod_annotation_prometheus_io_scrape_slow]
                        action: drop
                        regex: true
                      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scheme]
                        action: replace
                        regex: (https?)
                        target_label: __scheme__
                      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
                        action: replace
                        target_label: __metrics_path__
                        regex: (.+)
                      - source_labels:
                          [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
                        action: replace
                        regex: ([^:]+)(?::\d+)?;(\d+)
                        # NOTE: otel collector uses env var replacement. $$ is used as a literal $. We escape dollars once more as fluxcd also uses them.
                        # $$$$ =(fluxcd)> $$ =(otel)> $
                        replacement: $$$$1:$$$$2
                        target_label: __address__
                      - action: labelmap
                        regex: __meta_kubernetes_pod_annotation_prometheus_io_param_(.+)
                        replacement: __param_$$$$1
                      - action: labelmap
                        regex: __meta_kubernetes_pod_label_(.+)
                      - source_labels: [__meta_kubernetes_namespace]
                        action: replace
                        target_label: namespace
                      - source_labels: [__meta_kubernetes_pod_name]
                        action: replace
                        target_label: pod
                      - source_labels: [__meta_kubernetes_pod_phase]
                        regex: Pending|Succeeded|Failed|Completed
                        action: drop
                      - action: replace
                        source_labels: [__meta_kubernetes_pod_label_app_kubernetes_io_name]
                        target_label: job
                  # This job is setup to scrape the node metrics on the same host as the daemonset
                  # https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/29053
                  # - job_name: node-exporter
                  #   scrape_interval: 30s
                  #   relabel_configs:
                  #     - action: labelmap
                  #       regex: __meta_kubernetes_node_label_(.+)
                  #     - action: replace
                  #       regex: "(.*)"
                  #       replacement: "$$$$1"
                  #       separator: ";"
                  #       source_labels:
                  #         - job
                  #       target_label: __tmp_prometheus_job_name
                  #   static_configs:
                  #     - targets:
                  #         - $${env:OTEL_K8S_NODE_IP}:9100
                  # We still need to scrape kubelet's CAdvisor which isn't supported in any otel collector receiver
                  # https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/29053
                  - authorization:
                      credentials_file: "/var/run/secrets/kubernetes.io/serviceaccount/token"
                      type: Bearer
                    follow_redirects: true
                    honor_labels: true
                    honor_timestamps: true
                    job_name: kubelet
                    kubernetes_sd_configs:
                      - follow_redirects: true
                        role: node
                        selectors:
                          - role: node
                            # only scrape data from pods running on the same node as collector
                            field: "metadata.name=$${env:OTEL_K8S_NODE_NAME}"
                    metric_relabel_configs:
                      - action: drop
                        regex: container_cpu_(load_average_10s|system_seconds_total|user_seconds_total)
                        replacement: "$$$$1"
                        separator: ";"
                        source_labels:
                          - __name__
                      - action: drop
                        regex: container_fs_(io_current|reads_merged_total|sector_reads_total|sector_writes_total|writes_merged_total)
                        replacement: "$$$$1"
                        separator: ";"
                        source_labels:
                          - __name__
                      - action: drop
                        regex: container_memory_(mapped_file|swap)
                        replacement: "$$$$1"
                        separator: ";"
                        source_labels:
                          - __name__
                      - action: drop
                        regex: container_(file_descriptors|tasks_state|threads_max)
                        replacement: "$$$$1"
                        separator: ";"
                        source_labels:
                          - __name__
                      - action: drop
                        regex: container_spec.*
                        replacement: "$$$$1"
                        separator: ";"
                        source_labels:
                          - __name__
                      - action: drop
                        regex: ".+;"
                        replacement: "$$$$1"
                        separator: ";"
                        source_labels:
                          - id
                          - pod
                    metrics_path: "/metrics/cadvisor"
                    relabel_configs:
                      - action: replace
                        regex: "(.*)"
                        replacement: "$$$$1"
                        separator: ";"
                        source_labels:
                          - job
                        target_label: __tmp_prometheus_job_name
                      - action: replace
                        replacement: "kubelet"
                        target_label: job
                      - action: replace
                        regex: "(.*)"
                        replacement: "$$$$1"
                        separator: ";"
                        source_labels:
                          - __meta_kubernetes_node_name
                        target_label: node
                      - action: replace
                        regex: "(.*)"
                        replacement: https-metrics
                        separator: ";"
                        target_label: endpoint
                      - action: replace
                        regex: "(.*)"
                        replacement: "$$$$1"
                        separator: ";"
                        source_labels:
                          - __metrics_path__
                        target_label: metrics_path
                      - action: hashmod
                        modulus: 1
                        regex: "(.*)"
                        replacement: "$$$$1"
                        separator: ";"
                        source_labels:
                          - __address__
                        target_label: __tmp_hash
                      - action: keep
                        regex: "$(SHARD)"
                        replacement: "$$$$1"
                        separator: ";"
                        source_labels:
                          - __tmp_hash
                    scheme: https
                    scrape_interval: 15s
                    scrape_timeout: 10s
                    tls_config:
                      ca_file: "/var/run/secrets/kubernetes.io/serviceaccount/ca.crt"
                      insecure_skip_verify: true

          service:
            pipelines:
              logs:
                receivers: [otlp, filelog]
                processors: [k8sattributes, resourcedetection/env, batch]
                exporters: *victoriametrics-exporter
              metrics:
                receivers: [otlp, prometheus, hostmetrics, kubeletstats]
                processors: [k8sattributes, resourcedetection/env, batch]
                exporters: *victoriametrics-exporter

      cluster:
        enabled: true

        presets:
          kubernetesAttributes:
            enabled: true
          kubernetesEvents:
            enabled: true
          clusterMetrics:
            enabled: true
        

        # We wan't to keep a pod running
        podDisruptionBudget:
          minAvailable: 1
        
        config:
          receivers:
            k8sobjects:
              auth_type: serviceAccount
              objects:
                - name: pods
                  mode: pull
                - name: events
                  mode: watch

          service:
            pipelines:
              logs:
                receivers: [k8sobjects]
                processors: [k8sattributes, resourcedetection/env, batch]
                exporters: *victoriametrics-exporter
              metrics:
                receivers: [k8s_cluster]
                processors: [k8sattributes, resourcedetection/env, batch]
                exporters: *victoriametrics-exporter

    # extraObjects: